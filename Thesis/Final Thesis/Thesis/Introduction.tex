\chapter{Introduction}
\label{ch:introduction}

\highlight{I}n this chapter, we will introduce Energy-Efficient Neuromorphic Computing. Neuromorphic computing or brain-inspired computing is a way to mimic biological brain processing. Artificial neural network models the biological neural network. The biological neural network is a collection of interconnected neurons, A typical biological neuron consists of Dendrites, Soma, and Axon. Where each neuron receives signals from other neurons through dendrites and sends signals to other connected neurons through the axon. Soma is the functional unit of a neuron, the main process soma deals with is the accumulation of signals received through dendrites, and to activate the neuron. In general, a neuron can be in two states, Firing (activated state) or non-firing (deactivated) state. When a neuron sends output to other neurons, then the neuron is said to be in a firing state or in a non-firing state. The state of a neuron is decided by the incoming signals: if the summation of the input signals is more than a certain threshold, then the neuron is in an activated state, else it is in a deactivated state. In a similar fashion, the Artificial Neural Network (ANN) is modeled, which will be described in the upcoming sections. The demand for ANN is increasing tremendously. The number of applications of ANN is skyrocketing, some of the important applications to point out are Self-driving cars, Face recognition, Face detection, and Virtual assistants like Google Assistant, Siri, etc. Which uses a massive amount of neuromorphic computing. Usually, neuromorphic computing is performed on transistor-based devices. We aim to use spintronic devices which can be more energy-efficient than the traditional transistor-based devices. Apart from this, spintronic devices have some inherent advantages over transistor-based devices, like Weight, Sum, and Threshold function comes in-built, and spintronic devices are non-volatile in nature.

\section{Artifical Neural Network (ANN)}
Similar to a biological neural network, Artificial Neural Network is a collection of interconnected artificial neurons (or nodes). Like the biological counterpart, the artificial neuron takes multiple inputs, where each input is collected by the neuron through the edges, each edge has its own strength known as Weight. Each neuron has a summation block, an activation block, and a bias term. All the weighted inputs received by the artificial neuron and the bias term is at first sent into the summation block. The output of the summation block is fed into the activation block. The output of the activation block is the final output of the neuron. The weight and the bias term are the optimizing parameters of an ANN. It's a two-phase process, Training, and Evaluation. In the training phase, the neural network (NN) is trained on training data. Training data is a tuple (X, T), where X is the input and T is the desired output (or target). The training data is fed into the NN, the model learns the underlying feature of the data, and optimizes its weight and biases, so as to obtain a minimum error. Then comes the evaluation phase, in this phase, the trained NN is used to obtain the output for those inputs, which was never used in the training phase.
\subsection{Architecture}
We already stated that ANN is a system of interconnected neurons, but there is a specific architecture, by which the neurons are connected to each other. First of all, a NN consists of three layers: Input Layer, Hidden Layers, Output Layer

Input Layer:
This layer serves as the interface where the input to the NN is given by the user.

Output Layer:
This layer serves as the interface where the output from the NN is given to the user.

Hidden Layers:
The Hidden layer is not just one single layer like the Input and the Output Layer, this layer exists between the input layer and output layer where the majority of the computation of NN happens. Since the user does not interact with this layer, hence it is termed as the hidden layer.

Each layer consists of several neurons, based on the type of layer. The Input layer and the Output layer, the no. of neurons in these layers are decided by the problem at hand. Based on the problem requirement, these numbers are set. On the other hand, there is no particular rule for setting the number of neurons in hidden layers. In fact, the no. of hidden layers and the no. of neurons inside each layer are set during the training phase. 

The way the neurons are connected to each other is as follows:
The output of each neuron is connected to all other neurons in the next layer
There are no self-loops or feedback loops

\subsection{Activation Function}
Technically the activation function is a non-linear mathematical function. The activation function reflects the property of activation of a neuron in a biological NN. In ANN, similar to the biological NN, the neurons would not transmit signals to the next connected neuron unless a certain threshold is reached. The threshold is set by the bias component of a neuron. The most simplistic activation function, which also prevails in the biological NN is a step function, 
EQN 1
But generally in ANN, we use a much smoother version of the step activation function known as the Sigmoid activation function.
EQN 2
Often in the case of Deep Neural Networks, there may be millions-millions of neurons,  using the sigmoid function as an activation function will make it computationally expensive, hence another activation function is used known as Rectilinear Unit Function (ReLu). We will see in backpropagation why using ReLu will give more computational advantage over other activation functions.

\subsection{Forward Propagation}
In Forward-propagation, we need to set our neural architecture, after which the input traverses from the input layer to the output layer through the hidden layers. The weight and bias terms have already been configured. Here is an example: we have taken a very simple ANN with one neuron in the input layer, one in the output layer, and one hidden layer which consists of one neuron. With weights as W1 and W2, for edges connecting node 1 with 2 and node 2 with 3 respectively. X is the input given to the NN and Y is the output received from the NN. Node 2 and node 3 have the bias term B2 and B3 respectively. The following figure describes the neural architecture.

[fig of simple NN, in MID term press backup, slide 15]

Generally, the input node does not have any bias term; it's just a simple node, which accepts input and sends it to its subsequent connected node. 
Forward propagation steps:
Output from node 1, X
X travels through the edge of strength W1, hence the input received at node 2 is XW1, Z1=XW1
Node 2 processes the input (iz. Summation and activation) and gives the output, Z2=sigma(Z1 + B2) =sigma(X.W1 + B2)
Z2 travels through the edge of strength W2, hence the input received at node 3 is Z2.W2, Z3=Z2.W2
Node 3 process the input Z3, and gives the output, Y=sigma(Z3 +B3)=sigma( sigma(X.W1 + B2).W2+B3)
Which is the final output of the NN
\subsection{Gradient Descent}
We previously saw that ANN trains itself by minimizing error on changing the weight and biases. Gradient descent is an approach to do so. 
[fig mid term slide 16]
In the figure, we have Error in the y-axis and optimizing parameter K in the x-axis. K can be a weight or a bias term. Since weight and the bias term are the optimizing parameters of the NN, our goal is to choose such a value of K where the error becomes minimum. At first, we start at some initial point (initial K value), the initial point is chosen randomly, why it is chosen randomly will be explained shortly. The slope at that point is computed. The slope will suggest that in which direction of K, the minimum exists and at what rate the minimum should be reached. But the slope magnitude is generally high and there is a huge chance that it will overshoot the minimum point. Hence a learning rate (LR) is multiplied by the slope. LR is usually chosen small, but not very small. The step size is defined as Slope x LR. And the new K value is defined as Knew=K-step-size. This way the K takes larger jumps when it is far away from the minimum and it takes smaller jumps near the minimum. So that it does not overshoot. 
[fig mid term slide 17]
The optimizing term is chosen randomly at the beginning, because if the error plot turns out to be like the above plot, and we always start at some fixed initial point, then there is a high chance of getting stuck in a local minimum. Hence the K is chosen randomly to begin, so as to increase the probability of not getting stuck in a local minimum. This problem is unavoidable but it can be minimized.

\subsection{Backpropagation}
Backpropagation is the process in which the weight and biases are fine-tuned so as to decrease the error. It uses gradient descent, for minimization of error. Since it is done during the training phase, we use the training data, here also using the same ANN architecture as fig in Forward propagation. For simplicity, we have omitted the bias term. For input X, we have target value T, the output received from the NN, for input X is Y.
Error = (T-Y)2
Optimizing for W1, 
EQN 4

The steps through 1-4 are repeated until we get the minimum error, similarly, it is done for all the weights and biases in the NN.

\section{Character Recognition Model}
This is an implementation of ANN, where the NN model is given a set of noisy 7x5 pixels binary patterns of an alphabet, where each pixel value can be either 0 or 1. From the input, the model recognizes the alphabet despite having noises.
Here the input is a 35 (7x5)-bit word of the test character, e.g., 
A: 01110 10001 10001 11111 10001 10001 10001
And the output is a 26-bit word suggesting the alphabet
A: 10000000000000000000000000
B: 01000000000000000000000000 and so on

\subsection{Neural Architecture}
Input layer: It has 35 neurons, as it will receive 35-pixel values
Output layer: It has 26 neurons, as it will give a 26-bit word suggesting the alphabet 
Hidden Layers: Only 1 Hidden layer and there are 40 neurons in the hidden layer


\section{Neural Network using Spintronics}
An electron along with a charge also contains spin. We can use this spin to store and transmit binary information, we can encode UP spin as 0 and DOWN spin as 1. Spintronic devices are rapidly developing nano technologies, they can store, process and communicate. This is just a matter of spin rotation, since no charge movement, there is no ohmic dissipation, but there is dissipation due to magnetization damping. In order to change the spin, we need to apply external charge voltage/current, hence there is dissipation due to that. At 100 nm dimension, all the spins align in one direction, which can be represented as one single big spin.
\subsection{Magnetic Anisotropy}
Magnetic anisotropy means magnetization is not same in all directions. The magnetization of a specimen depends on its shape. When a specimen of finite size is magnetized by an external magnetic field, the free poles which appear on its ends will produce a magnetic field directed opposite to the magnetization. This field is called the demagnetizing field. The intensity of the demagnetizing field $H_d$ is proportional to the magnetic free pole density and therefore to the magnetization
\[H_d=N_d\frac{I}{\mu_0}\]
where $N_d$ is the demagnetizing factor, which depends on the shape of the specimen.\\
In case of a sphere, because of it total symmetry, the demagnetization factor is same in all direction, hence there is no anisotropy.
In case of an ellipsoid,as it is not symmetric in all direction, anisotropy exists but because of its shape, it is difficult to fabricate in a planar wafer.
Which brings us to elliptical cylinder, it has anisotropy and because of its planar surface, it is easy to fabricate on a planar wafer. The elliptical cylinder poses the in-plane shape magnetic anisotropy. The energy of the same is given by $E=\frac{1}{2}\Omega M_s H_k sin^2 \theta$, where the $\Omega$ is the volume of the elliptical cylinder, $M_s$ is the saturation magnetization, $H_k$ is the coercive field

\subsection{Magnetic Field along in-plane: Easy and Hard axis}
\begin{figure}[H]
	\centering
   \includegraphics[scale=0.56]{Images/19.png} 
   \caption{Elliptical cylinder}
\end{figure} 
Switching magnetization from one direction to opposite direction by application of magnetic field in In-plane easy and hard axis. \\
In the Fig. 1.1, we have an elliptical cylinder whose major-axis is in the $\hat{z}$ direction, the minor-axis is in $\hat{y}$ direction and the thickness is in the $\hat{x}$ direction\\\\

\textbf{For In-plane hard axis}\\
\begin{figure}[H]
	\centering
   \includegraphics[scale=0.56]{Images/20.png} 
   \caption{In-plane hard axis: Energy vs $\theta$}
\end{figure}
The magnetic field (\textbf{$H_y$}) is applied along the $\hat{y}$ direction of the elliptical cylinder. The magnetization vector of the cylinder is making an angle $\theta$ with the z-axis. Let's say, initially the magnetization vector is along the z-axis (i.z. $\theta=0^o$), on application of magnetic field $H_y$ can the magnetization vector be made align in (-z)-axis (i.z. $\theta=180^o$)

The anisotropic energy is given by 
\[E=\frac{1}{2}\mu_0M_sH_ksin^2\theta - \mu_0M_sH_ysin\theta\]
In Fig. 1.2, anisotropic energy is plotted against $\theta$($0^o - 180^o$) for different values of $H_y$.\\
For a given value of $H_y$, the magnetization vector aligns such that the anisotropic energy is minimum. Hence, \[\frac{dE}{d\theta}=0 \implies \theta_{min}=sin^{-1}(H_y/H_k)\]
The $\theta_{min}$ decides the angle made by the magnetization vector with the z-axis. \\
When $H_y=0$, $\theta_{min}$ comes out to be $0^o$ ,and there is a potential barrier at $\theta=90^o$, which prevents the magnetization flipping from $\theta=0^o$ to $180^o$. \\
As $H_y$ is increased gradually, the potential barrier at $\theta=90^o$ decreases and the $\theta_{min}$ shifts away from $\theta=0^o$, for example, when $H_y=0.7H_k$, $\theta_{min}=45^o$, i.z. on applying $H_y=0.7H_k$, the magnetization vector is making an angle of $75^o$ with the z-axis.\\\\
When $H_y=H_k$, $\theta_{min}=90^o$ and there is no potential barrier. But on further increasing the $H_y$ to however large value, the $\theta_{min}$ does not change, and it still remains at $\theta_{min}=90^o$.\\
Which suggest that on application of magnetic field along in-plane hard axis will not be able to switch the magnetization to the opposite direction.\\\\

\textbf{For In-plane easy axis}\\
\begin{figure}[H]
	\centering
   \includegraphics[scale=0.56]{Images/21.png} 
   \caption{In-plane easy axis: Energy vs $\theta$}
\end{figure}
When the magnetic field is applied along the $\hat{z}$ direction of the elliptical cylinder.The anisotropic energy is given by 
\[E=\frac{1}{2}\mu_0M_sH_ksin^2\theta - \mu_0M_sH_zcos\theta\]
For a given value of $H_z$, the magnetization vector aligns at an angle $\theta_{min}=sin^{-1}(H_z/H_k)$
In Fig. 1.3, anisotropic energy is plotted against $\theta$($0^o - 180^o$) for different values of $H_z$.
When $H_z=0$, $\theta_{min}$ comes out to be $0^o$ ,and there is a potential barrier at $\theta=90^o$, which prevents the magnetization flipping from $\theta=0^o$ to $180^o$. \\
On increasing the $H_z$, the energy at $\theta=0^o$ side increases and $\theta=180^o$ side decreases, thereby reducing the potential barrier.\\
When $H_z=H_k$, $\theta_{min}=90^o$ and instead of a potential barrier there is a potential slope. So on further increasing the $\theta_{min}$ becomes $180^o$\\
Which concludes that when magnetic field is applied along the in-plane easy axis direction, magnetization switching is possible.  

\subsection{Perpendicular Magnetic Anisotropy}
\begin{figure}[H]
	\centering
   \includegraphics[scale=0.56]{Images/22.png} 
   \caption{Perpendicular magnetic anisotropy}
\end{figure}
When the magnetization is perpendicular to the planar surface, we have perpendicular magnetic anisotropy. For easy axis, $\theta = 0^o$ and $180^o$ and for the hard axis, $\theta = 90^o$.  The magnet's plane is $\phi=90^o$. Perpendicular magnetic anisotropy is essential as it decreases the lateral dimension, just like transistor scaling, it can accommodates more number of similar magnets in an area.
\begin{figure}[H]
	\centering
   \includegraphics[scale=0.56]{Images/23.png} 
   \caption{Perpendicular magnetic anisotropy: a. Bulk anisotropy b. Interface anisotropy}
\end{figure}
There are two type of perpendicular anisotropy: a. Bulk anisotropy and b. Interface anisotropy\\

\subsection{Magnetostriction}
Magnetostriction is a phenomenon where the shape of a ferromagnetic material changes during the process of magnetization. The deformation or the strain $ \frac{\partial l}{l}$ generated is usually small and in the range $10^{-5}$ to $10^{-6}$.\\
On increasing the magnitude of magnetic field, the magnetostriction strain increases. After a certain magnetic field the strain reaches a saturation value $\lambda$ and known as the magnetostrictive co-efficient.
\begin{figure}[H]
	\centering
   \includegraphics[scale=0.56]{Images/24.png} 
   \caption{Magnetostriction elongation as a function of applied field}
\end{figure}
The reason behind this phenomenon is the crystal structure inside the domain spontaneously deforms in the direction of magnetization and the strain axis rotates with the magnetization creating a deformation therby generating strain.\\
The spontaneous strain in the domain is expressed as $e=\frac{3}{2} \lambda$\\
The magnetostriction strain depends on the angle $\psi$, made by the applied magnetic field with the easy axis of the ferromagnetic specimen.
\[\Delta(\frac{\partial l}{l})=\frac{3}{2}\lambda(1-cos^2\psi)\]
The higher the magnetic field, the domain magnetization rotates more towards the direction of the applied field. If H is parallel to the easy axis $\Delta(\frac{\partial l}{l})=0$, that is there will be no elongation or no strain generated.
\subsection{Multiferroics and Multiferroic Composites}
\begin{figure}[H]
	\centering
   \includegraphics[scale=0.56]{Images/18.png} 
   \caption{â€¢}
\end{figure}
In nature there exist, ferroelectric and ferromagnetic materials. Ferroelectric materials are those materials whose polarization changes on changing the electric field and vice versa, similar to ferro-electric, the ferromagnetic materials are those materials whose magnetization changes on changing the magnetic field and vice verse. There are certain materials which posses both the properties of ferroelectric and ferromagnetic materials. These materials are known as multiferroics. For a multiferroic material, the polarization changes on changing the magnetic field and the magnetization changes on changing the electric field.\\   
In the Figure 1.1, the outer node of the triangle which consists of Electric field \textbf{E}, Magnetic field \textbf{H}, and the Stress \textbf{$\sigma$} are the physical parameters which can be changed, and the inner node of the triangle which consists of Polarization \textbf{P}, Strain \textbf{$\epsilon$}, and the Magnetization \textbf{M} are the  macroscopic observables of the respective physical parameter.\\
Ferroelectric material: change in E leads to change in P\\
Ferromagnetic material: change in H leads to change in M and\\
Ferroelastic material: change in $\sigma$ leads to change in $\epsilon$\\
For multiferroic material there is an intrinsic coupling between \textbf{E} and \textbf{H}, known as Magneto-electric coupling
\[\alpha_{ME}=\mu_0\frac{\partial M}{\partial E}\]
At room temperature the magneto-electric coupling is very weak. So instead of a multiferroics, we use a multiferroic composite, which is a composite of pizeoelectric and magnetostrictive material. Piezoelectric materials are those materials, on applying electric field, stress is generated at the body and vice versa, and magnetostrictive material are those materials which generates stress on application of magnetic field, and vice versa. The composition of piezoelectric and magnetostrictive material serves the same purpose of multiferroics with strong magneto-electric coupling. Multiferroic composites are stress mediated materials.
\[\alpha_{ME}=\mu_0\frac{\partial M}{\partial \sigma}\frac{\partial \sigma}{\partial E}\] 

\subsection{Giant Magneto Resistance (GMR)}
\begin{figure}[H]
	\centering
   \includegraphics[scale=0.56]{Images/25.png} 
   \caption{Giant Magneto Resistance}
\end{figure}
In 2007, Nobel prize in physics was awarded jointly to Albert Fert and Peter Grunberg, for the discovery of Giant magnetic resistance. In the Figure 1.8(a), there is a structure Fe/Cr/Fe, it is seen that on application of magnetic field the resistance along the structure reduces. In Figure 1.8(b), the resistance ratio vs Magnetic field is plotted against three different thick of  the chromium layer.\\
The origin of the phenomenon is that the magnetization of the Fe layers in the either side of the Cr layer are in anti-parallel orientation as a result of negative exchange interaction through the Cr layer. On application of magnetic field, the spin-dependent magnetic scattering of conduction electron is reduced, which causes a parallel orientation.\\
The GMR is calculated as follows
\[GMR=\frac{R(0)-R(H)}{R(H)}\]
where $R(0)$ refers to resistance when no magnetic field is applied, $R(H)$ refers to resistance when magnetic field is applied.
\subsection{Tunnelling Magneto Resistance (TMR)}
\begin{figure}[H]
	\centering
   \includegraphics[scale=0.56]{Images/26.png} 
   \caption{Tunnelling Magneto Resistance}
\end{figure}
Magnetic tunnelling is observed for two ferromagnetic metal layers separated by a thin insulating materials like $Al_2O_3$, $MgO$. Similar to GMR, in case of TMR, when the magnetization on both the ferromagnetic layers are in parallel orientation, resistance is low and when they are in anti-parallel orientation, the resistance is high.\\
This phenomenon occurs because below the fermi level, for a UP magnetization, the density of UP states is higher than the density of DOWN states.Similarly, for DOWN magnetization, the density of the DOWN state is higher than the density of UP state.\\
So for parallel orientation as shown in the Figure 1.9, for both side of the insulator, below the fermi level, the density of UP state is equal on both side, similar is the case for DOWN state. Hence, the states or the electrons can easily tunnel, and results in low resistance. But in case of anti-parallel orientation, the respective density of states are not same on the both side. In Figure 1.9, for the anti-parallel case, the density of UP state is high in the left side while the density of UP state in the left side low. Hence the electrons can not easily tunnel through the insulator, and results in increasing resistance.   
\section{Magnetic Thermal Annealing}
Lattice and shape deformities in a material can significantly degrades its quality. Thermal annealing is a common technique used to strengthen the solid by raising, maintaining, and slowly decreasing the temperature. Raising the temperature allows the atoms to diffuse more easily to their proper location, and maintaing the temperature attains equilibrium, eliminating any structural imperfections.\\
When magnetic field is applied during the thermal annealing process, it is known as Magnetic thermal annealing. It has some interesting effect in ferromagnetic materials. The most important one is the re-orientation of the easy axis of a magnetic material. In any magnetic material, the easy axis is determined by the lattice structure of the material. If the shape shows any symmetry , the easy axis will normally reflect this symmetry. Now if there are many structural deformities , then there would be no global symmetry and the easy axis will be randomized.\\
When a deformed ferromagnetic material is thermally annealed in presence of an externally applied magnetic field, the spins of each individual atom will align the direction of the applied magnetic field. When maintained at high temperature, the system will attain equilibrium within this field, causing a lattice re-orientation such that easy axis is parallel to the applied magnetic field.
\subsection{Magnetic Thermal Annealing experimental system}
\begin{figure}[H]
%\begin{subfigure}
	\centering
   \includegraphics[scale=0.56]{Images/27.png} 
   \caption{Magnetic Thermal Annealing experimental system}
   %\end{subfigure}
\end{figure}
In Figure 1.10, the experimental set-up for magnetic thermal annealing is shown. Where there is an electromagnet which provides constant DC magnetic field, there is a Constant Current Power Supply (CCPS) to provide constant current to the electromagnet, there is a chiller, to liquid cool the coils of the electromagnet, then there is the annealing set-up, inside which sample is placed. Inside the annealing set-up, there is a thermocouple, which generates heat. The thermocouple is connected to the heater PID which controls the amount and the duration of heating. The magnetic thermal annealing is done in vacuum, for which there is a rotatory vacuum pump connected to the annealing set-up. To monitor the vacuum pump pressure, a pirani gauge is connected to the vacuum pump.    
\section{Ferro-magnteic Resonance (FMR)}
When a magnetic material is placed in a DC magnetic field, the magnetization vector rotates in counter-clock wise direction, along the direction of the DC field. This is called the precessional motion of the magnetization vector, as it does, it losses energy, the rotational body falls in the direction of the DC field, this is known as damping. This precesssing of magnetization vector is captured by the   Landau-Lifshitz Equation (LL Equation):
\[\frac{dM}{dt}=-|\gamma|M\times H_{eff} - \frac{\alpha |\gamma|}{M}M\times M\times H_{eff}\]
where $\alpha$ and $\gamma$ are the damping parameter and the Gyromagnetic ratio of the magnetic material respectively.\\
In FMR experiment our aim is to find $\alpha$ of the magnetic material.\\
We will consider $\alpha$ later. The precessional motion of the magnetization vector is given by 
\[\frac{dM}{dt}=-|\gamma|M\times H_{eff}\]
DC magnetic field is applied along the z-axis, hence $M_z=M$, and the $M_x$ and $M_y$ has $e^{-i\omega t}$ dependence, hence
\[\frac{dM_x}{dt}=-|\gamma|(H_z + (N_{yy}-N_{zz})M)M_y\]
and
\[\frac{dM_y}{dt}=|\gamma|(H_z + (N_{xx}-N_{zz})M)M_x\]
Solving the above two equation, we get
\[\omega^2=|\gamma|^2(H_z + (N_{yy}-N_{zz})M)(H_z+(N_{xx}-N_{zz})M)\]
In case of, sphere: $N_{xx}=N_{yy}=N_{zz}$, therefore, $\omega =|\gamma|H_z$\\
In-plane FMR: $N_{xx}=N_{zz}=0, N_{yy}=1$, therefore, $\omega =|\gamma|\sqrt{H_z(H_z+M)}$\\
Perpendicular FMR:  $N_{xx}=N_{yy}=0, N_{zz}=1$, therefore, $\omega =|\gamma|(Hz-M)$\\
On Linearizing the small rotations,
\[\frac{d^2\phi}{dt^2}+\alpha|\gamma|M\frac{d\phi}{dt}+\omega_0^2\phi=0\]
where $\omega_0=|\gamma|\sqrt{H_z(H_z+M)}$, for IN-plane FMR\\
To negative the damping, and to keep the magnetization rotating, a transverse AC field $H_y(t)=H_{y0}e^{i\omega t}$ is applied
\[\frac{d^2\phi}{dt^2}+\alpha|\gamma|M\frac{d\phi}{dt}+\omega_0^2\phi =|\omega|^2MH_{y0}e^{i\omega t} \]
On solving the differential equation, $\phi(t)=\phi_0e^{i\omega t}=|\phi_0|e^{i(\omega t+\delta)}$, where\\
\[\phi_0=\frac{|\gamma|^2MH_{y0}}{(\omega_0^2 - \omega^2)^2 + (\alpha|\gamma|M\omega)^2}[(\omega_0^2 - \omega^2)-i\alpha|\gamma|M\omega]\]
\[|\phi_0|=\frac{|\gamma|^2MH_{y0}}{\sqrt{(\omega_0^2 - \omega^2)^2 + (\alpha|\gamma|M\omega)^2}}, tan \delta = \frac{-\alpha|\gamma|M\omega}{(\omega_0^2 - \omega^2)}\]
The FMR absorption is given by the Imag($\phi_0$), known as the Lorentzian
\[Imag(\phi_0)=\frac{|\gamma|^2MH_{y0}\alpha|\gamma|M\omega}{(\omega_0^2 - \omega^2)^2 + (\alpha|\gamma|M\omega)^2}\]
at $\omega=\omega_0$, $Imag(\phi_0)=\frac {H_{y0}|\gamma|}{\alpha \omega_0}$\\
The FMR linewidth $\Delta H$, Half width at half maximum (HWHM) is given by:
\[\Delta H =\frac{\alpha\omega_0}{|\gamma|}\]
\section{Magnetic Force Microscopy (MFM)}
\section{Piezo Force Microscopy (PFM)}
\section{Vibrating Sample Magnetometer (VSM)}
\section{X-ray Diffraction (XRD)}
\section{X-ray Reflectivity (XRR)}
\section{Strain-gauge}
\section{Stress-strain Testing Machine}
\section{Proposed Device}

\section{Experimental Apparatus}
This list of experimental apparatus used in the entire project is mentioned here
\subsection{Spin Coater}
\begin{figure}[H]
	\centering
   \includegraphics[scale=0.56]{Images/4.png} 
   \caption{Spin Coater}
\end{figure}
For spin-coating EBL photo-resist of 100 nm thickness on a Si substrate a Holmarc Spin-coater is used. It has a nylon bowl, inside which there is a chuck which holds the sample using a vacuum pump. In the front-panel, there is a LCD display and keyboard to program the Spin-coaters rotation speed, acceleration, time period of rotation, and number of steps.  

\subsection{Shaker}
\begin{figure}[H]
	\centering
   \includegraphics[scale=0.56]{Images/5.png} 
   \caption{Shaker}
\end{figure}
To shake or mixing chemicals, the shaker is used. It has adjustable rollers which helps in fixing the beaker firmly on the movable platform. On the front-panel there are buttons to set the RPM and the time duration.

\subsection{Hot Plate}
\begin{figure}[H]
	\centering
   \includegraphics[scale=0.56]{Images/6.png} 
   \caption{Hot plate}
\end{figure}
To bake samples at high temperature, a hot plate is used. It has a ceramic platform, over which samples are placed. The ceramic plate can go up to $550^o C$. In the front-panel there buttons to set the temperature, timer and start/stop button. 

\subsection{Ultrasonic Cleaner}
\begin{figure}[H]
	\centering
   \includegraphics[scale=0.56]{Images/7.png} 
   \caption{Ultrasonic Cleaner}
\end{figure}
To clean samples, beakers or other apparatus by vibrating at high frequency. Samples are placed inside a cleaner, with appropriate solvent which gets cleaned on vibrating. In the front-panel there are buttons for Start/Stop, timer, temperature.   

\subsection{Hot Air Oven}
\begin{figure}[H]
	\centering
   \includegraphics[scale=0.56]{Images/8.png} 
   \caption{Hot Air Oven}
\end{figure}


\subsection{Rota Mantle}
\begin{figure}[H]
	\centering
   \includegraphics[scale=0.56]{Images/9.png} 
   \caption{Rota Mantle}
\end{figure}

\subsection{Nitrogrn Gun}
\begin{figure}[H]
	\centering
   \includegraphics[scale=0.56]{Images/10.png} 
   \caption{Nitrogen Gun}
\end{figure}

\subsection{Vacuum Desiccator}
\begin{figure}[H]
	\centering
   \includegraphics[scale=0.56]{Images/11.png} 
   \caption{Vacuum Desiccator}
\end{figure}

\subsection{Muffle Furnace}
\begin{figure}[H]
	\centering
   \includegraphics[scale=0.56]{Images/12.png} 
   \caption{Muffle Furnace}
\end{figure}

\subsection{Fume Hood}
\begin{figure}[H]
	\centering
   \includegraphics[scale=0.56]{Images/13.png} 
   \caption{Fume Hood}
\end{figure}

\subsection{Source Measuring Unit (SMU)}
\begin{figure}[H]
	\centering
   \includegraphics[scale=0.56]{Images/14.png} 
   \caption{Source Measuring Unit}
\end{figure}

\subsection{Power Supply}
\begin{figure}[H]
	\centering
   \includegraphics[scale=0.56]{Images/15.png} 
   \caption{Power Supply}
\end{figure}

\subsection{Probe Station}
\begin{figure}[H]
	\centering
   \includegraphics[scale=0.56]{Images/16.png} 
   \caption{Probe Station}
\end{figure}

\subsection{Oscilloscope}
\begin{figure}[H]
	\centering
   \includegraphics[scale=0.56]{Images/17.png} 
   \caption{Oscilloscope}
\end{figure}

\section{LabView measurement automation}


\section{\label{sec:outline}Outline of the remaining chapters}

The outline of the remaining chapters are as follows. Chapter~\ref{ch:results} provides the results ... 

Physics of Ferromagnetism~\cite{chika97}, Brown~\cite{brown68}